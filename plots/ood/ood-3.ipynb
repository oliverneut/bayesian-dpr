{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd286dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from types import SimpleNamespace\n",
    "from vbll.layers.regression import VBLLReturn\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "base_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.append(base_path)\n",
    "\n",
    "from src.utils.data_utils import DatasetConfig\n",
    "from src.data_loaders import get_queries, get_qrels\n",
    "from src.utils.model_utils import vbll_model_factory, model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c82aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_queries(data: list, data_dir: Path, split: str) -> None:\n",
    "    \"\"\"Save queries to file.\"\"\"\n",
    "    with open(data_dir / f'queries-{split}.jsonl', 'wt', encoding='utf8') as f_out:\n",
    "        for query_data in tqdm(data, desc=f\"Saving {split} queries\"):\n",
    "            json.dump({\"query\": query_data[\"query\"], \"OOD\": query_data[\"OOD\"]}, f_out)\n",
    "            f_out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c106f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_queries(test_queries: list, queries: Dict, data_cfg: DatasetConfig, num_samples: int, OOD: bool) -> None:\n",
    "    \"\"\"Prepare test queries dataset.\"\"\"\n",
    "    qrels = get_qrels(data_cfg.get_qrels_file(split=data_cfg.test_name))\n",
    "    \n",
    "    i = 0\n",
    "    for qid, rels in qrels.items():\n",
    "        if len(rels) > 0:\n",
    "            test_queries.append({\"query\": queries[qid], \"OOD\": OOD})\n",
    "            i += 1\n",
    "        \n",
    "        if i >= num_samples: break\n",
    "    \n",
    "    return test_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6217fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_cfg = DatasetConfig('msmarco')\n",
    "nq_cfg = DatasetConfig('nq')\n",
    "hotpotqa_cfg = DatasetConfig('hotpotqa')\n",
    "fiqa_cfg = DatasetConfig('fiqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f60f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_queries = get_queries(msmarco_cfg.get_queries_file())\n",
    "nq_queries = get_queries(nq_cfg.get_queries_file())\n",
    "hotpotqa_queries = get_queries(hotpotqa_cfg.get_queries_file())\n",
    "fiqa_queries = get_queries(fiqa_cfg.get_queries_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb0f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"10nfecme\"\n",
    "args = OmegaConf.load(f'{base_path}/config.yml')\n",
    "api = wandb.Api()\n",
    "config = api.run(f\"{args.wandb.entity}/{args.wandb.project}/{run_id}\").config\n",
    "params = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd3361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverneut/miniconda3/envs/bret/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /Users/oliverneut/Desktop/vbll-retrieval/output/models/10nfecme/model.pt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_dir = f\"{base_path}/output/models/{run_id}\"\n",
    "model_path = f\"{save_dir}/model.pt\"\n",
    "\n",
    "tokenizer, model = vbll_model_factory(params.model_name, device)\n",
    "method = \"vbll\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(f'Loaded model from {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10d315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_query(qry: str, tokenizer, model):\n",
    "    qry_enc = tokenizer(qry, padding=\"max_length\", truncation=True, max_length=32, return_tensors=\"pt\")\n",
    "    qry_emb = model(qry_enc)\n",
    "    return qry_emb\n",
    "\n",
    "def uncertainty_score(qry_emb, unc_method=\"norm\"):\n",
    "    cov = qry_emb.covariance.squeeze()\n",
    "\n",
    "    if unc_method == \"norm\":\n",
    "        return torch.sqrt(qry_emb.trace_covariance)\n",
    "    elif unc_method == \"trace\":\n",
    "        return qry_emb.trace_covariance\n",
    "    elif unc_method == \"det\":\n",
    "        return qry_emb.logdet_covariance\n",
    "    elif unc_method == \"entropy\":\n",
    "        d = cov.size(0)\n",
    "        logdet = qry_emb.logdet_covariance\n",
    "        return 0.5 * d * torch.log(torch.tensor(2 * torch.pi * torch.e)) + 0.5 * logdet\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown uncertainty method: {unc_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd741a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uncertainty_scores(data, tokenizer, model, unc_method=\"norm\"):\n",
    "    uncertainty_scores = []\n",
    "    labels = []\n",
    "    for query_data in tqdm(data, desc=\"Calculating uncertainty scores\"):       \n",
    "        emb = infer_query(query_data['query'], tokenizer, model)\n",
    "\n",
    "        uncertainty_scores.append(uncertainty_score(emb.predictive, unc_method).item())\n",
    "        labels.append(query_data['OOD'])\n",
    "\n",
    "    return np.array(uncertainty_scores), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08276572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msp_score(logits):\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    return 1 - probs.max(dim=-1).values\n",
    "\n",
    "def entropy_score(logits):\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    log_probs = torch.log(probs + 1e-12)\n",
    "    return -(probs * log_probs).sum(dim=-1)\n",
    "\n",
    "def energy_score(logits, temperature=1.0):\n",
    "    return -temperature * torch.logsumexp(logits / temperature, dim=-1)\n",
    "\n",
    "def calculate_baseline_scores(data, tokenizer, model):\n",
    "    msp_scores = []\n",
    "    entropy_scores = []\n",
    "    energy_scores = []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for query_data in tqdm(data, desc=\"Calculating uncertainty scores\"):  \n",
    "        emb = infer_query(query_data['query'], tokenizer, model)\n",
    "        if isinstance(emb, VBLLReturn):\n",
    "            emb = emb.predictive.loc\n",
    "        msp_scores.append(msp_score(emb).item())\n",
    "        entropy_scores.append(entropy_score(emb).item())\n",
    "        energy_scores.append(energy_score(emb).item())\n",
    "        \n",
    "        labels.append(query_data['OOD'])\n",
    "\n",
    "    return np.array(msp_scores), np.array(entropy_scores), np.array(energy_scores), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85089685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(uncertainty_scores, labels):\n",
    "    auc = roc_auc_score(labels, uncertainty_scores)\n",
    "    print(f\"AUROC: {auc}\")\n",
    "    aupr = average_precision_score(labels, uncertainty_scores)\n",
    "    print(f\"AUPR: {aupr}\")\n",
    "    pbs = pointbiserialr(labels, uncertainty_scores)\n",
    "    print(f\"Point Biserial Correlation: {pbs.correlation}, p-value: {pbs.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5e3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_nq_queries = []\n",
    "msmarco_nq_queries = prepare_test_queries(msmarco_nq_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_nq_queries = prepare_test_queries(msmarco_nq_queries, nq_queries, nq_cfg, 1000, OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a36182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:44<00:00, 44.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty scores calculated using method norm\n",
      "AUROC: 0.47761050000000005\n",
      "AUPR: 0.48273771023740375\n",
      "Point Biserial Correlation: -0.04650204584722596, p-value: 0.0375751365606453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:44<00:00, 45.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.525672\n",
      "AUPR: 0.5151179952637311\n",
      "Point Biserial Correlation: 0.02809978149238754, p-value: 0.20907144432141286\n",
      "AUROC: 0.523807\n",
      "AUPR: 0.5211572527710577\n",
      "Point Biserial Correlation: 0.0407419799981015, p-value: 0.0685075050534339\n",
      "AUROC: 0.531596\n",
      "AUPR: 0.5335598105542054\n",
      "Point Biserial Correlation: 0.0602108317727549, p-value: 0.007071235899221918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unc_method = \"norm\"\n",
    "uncertainty_scores, labels = calculate_uncertainty_scores(msmarco_nq_queries, tokenizer, model, unc_method=\"norm\")\n",
    "print(f\"Uncertainty scores calculated using method {unc_method}\")\n",
    "metrics(uncertainty_scores, labels)\n",
    "print('')\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_nq_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baba39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_hotpotqa_queries = []\n",
    "msmarco_hotpotqa_queries = prepare_test_queries(msmarco_hotpotqa_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_hotpotqa_queries = prepare_test_queries(msmarco_hotpotqa_queries, hotpotqa_queries, hotpotqa_cfg, 1000, OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8791a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:43<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty scores calculated using method norm\n",
      "AUROC: 0.08227199999999998\n",
      "AUPR: 0.3238643132527613\n",
      "Point Biserial Correlation: -0.7061367607382435, p-value: 7.268151566712335e-302\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:44<00:00, 45.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.528875\n",
      "AUPR: 0.49732584303801497\n",
      "Point Biserial Correlation: -0.017223619734340057, p-value: 0.44139526048974737\n",
      "AUROC: 0.538689\n",
      "AUPR: 0.5072515442807781\n",
      "Point Biserial Correlation: 0.0336054746041069, p-value: 0.13300228567433267\n",
      "AUROC: 0.6045195\n",
      "AUPR: 0.5621183791642528\n",
      "Point Biserial Correlation: 0.19973672571349443, p-value: 1.9167873718608717e-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unc_method = \"norm\"\n",
    "uncertainty_scores, labels = calculate_uncertainty_scores(msmarco_hotpotqa_queries, tokenizer, model, unc_method=unc_method)\n",
    "print(f\"Uncertainty scores calculated using method {unc_method}\")\n",
    "metrics(uncertainty_scores, labels)\n",
    "print('')\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_hotpotqa_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_fiqa_queries = []\n",
    "msmarco_fiqa_queries = prepare_test_queries(msmarco_fiqa_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_fiqa_queries = prepare_test_queries(msmarco_fiqa_queries, fiqa_queries, fiqa_cfg, 1000, OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01df336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 1500/1500 [00:34<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty scores calculated using method norm\n",
      "AUROC: 0.67563\n",
      "AUPR: 0.7783423089014669\n",
      "Point Biserial Correlation: 0.3218775548937509, p-value: 1.6825287642309795e-37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 1500/1500 [00:33<00:00, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.547342\n",
      "AUPR: 0.7398583176287041\n",
      "Point Biserial Correlation: 0.14415916727951011, p-value: 2.0477022593974783e-08\n",
      "AUROC: 0.540356\n",
      "AUPR: 0.7366394437197772\n",
      "Point Biserial Correlation: 0.11477959523501863, p-value: 8.333814981161278e-06\n",
      "AUROC: 0.5137849999999999\n",
      "AUPR: 0.719545840216764\n",
      "Point Biserial Correlation: 0.008305829425592725, p-value: 0.7478915514013337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uncertainty_scores, labels = calculate_uncertainty_scores(msmarco_fiqa_queries, tokenizer, model, unc_method=\"norm\")\n",
    "print(f\"Uncertainty scores calculated using method {unc_method}\")\n",
    "metrics(uncertainty_scores, labels)\n",
    "print('')\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_fiqa_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38d34a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"yi84sy0n\"\n",
    "args = OmegaConf.load(f'{base_path}/config.yml')\n",
    "api = wandb.Api()\n",
    "config = api.run(f\"{args.wandb.entity}/{args.wandb.project}/{run_id}\").config\n",
    "params = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b29395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverneut/miniconda3/envs/bret/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /Users/oliverneut/Desktop/vbll-retrieval/output/models/yi84sy0n/model.pt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_dir = f\"{base_path}/output/models/{run_id}\"\n",
    "model_path = f\"{save_dir}/model.pt\"\n",
    "\n",
    "tokenizer, model = model_factory(params.model_name, device)\n",
    "method = \"vbll\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(f'Loaded model from {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e705bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:38<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.3251635\n",
      "AUPR: 0.3870879685132027\n",
      "Point Biserial Correlation: -0.2912875530984401, p-value: 2.0724625916697796e-40\n",
      "AUROC: 0.2975735\n",
      "AUPR: 0.3746156848346671\n",
      "Point Biserial Correlation: -0.3562519724269746, p-value: 6.510096012965339e-61\n",
      "AUROC: 0.308416\n",
      "AUPR: 0.37922080807658354\n",
      "Point Biserial Correlation: -0.3391698477462174, p-value: 4.990034077487274e-55\n"
     ]
    }
   ],
   "source": [
    "msmarco_nq_queries = []\n",
    "msmarco_nq_queries = prepare_test_queries(msmarco_nq_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_nq_queries = prepare_test_queries(msmarco_nq_queries, nq_queries, nq_cfg, 1000, OOD=True)\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_nq_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ade17695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 2000/2000 [00:40<00:00, 49.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.17428500000000002\n",
      "AUPR: 0.33581042164270286\n",
      "Point Biserial Correlation: -0.5290336783813766, p-value: 1.1941099073968296e-144\n",
      "AUROC: 0.05588950000000001\n",
      "AUPR: 0.3131043782951018\n",
      "Point Biserial Correlation: -0.7469927658654278, p-value: 0.0\n",
      "AUROC: 0.0627865\n",
      "AUPR: 0.31388121609946895\n",
      "Point Biserial Correlation: -0.7342374998637424, p-value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "msmarco_hotpotqa_queries = []\n",
    "msmarco_hotpotqa_queries = prepare_test_queries(msmarco_hotpotqa_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_hotpotqa_queries = prepare_test_queries(msmarco_hotpotqa_queries, hotpotqa_queries, hotpotqa_cfg, 1000, OOD=True)\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_hotpotqa_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b60c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores:   0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating uncertainty scores: 100%|██████████| 1500/1500 [00:34<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline scores calculated\n",
      "AUROC: 0.322836\n",
      "AUPR: 0.24314550845275426\n",
      "Point Biserial Correlation: -0.28614438280964427, p-value: 1.165515795727049e-29\n",
      "AUROC: 0.187816\n",
      "AUPR: 0.2101922457131668\n",
      "Point Biserial Correlation: -0.5071649098866916, p-value: 7.657117787132468e-99\n",
      "AUROC: 0.20453000000000002\n",
      "AUPR: 0.21340164975690346\n",
      "Point Biserial Correlation: -0.48145016550341263, p-value: 7.133268741670028e-88\n"
     ]
    }
   ],
   "source": [
    "msmarco_fiqa_queries = []\n",
    "msmarco_fiqa_queries = prepare_test_queries(msmarco_fiqa_queries, msmarco_queries, msmarco_cfg, 1000, OOD=False)\n",
    "msmarco_fiqa_queries = prepare_test_queries(msmarco_fiqa_queries, fiqa_queries, fiqa_cfg, 1000, OOD=True)\n",
    "\n",
    "msp_scores, entropy_scores, energy_scores, labels = calculate_baseline_scores(msmarco_fiqa_queries, tokenizer, model)\n",
    "print(f\"Baseline scores calculated\")\n",
    "metrics(msp_scores, labels)\n",
    "metrics(entropy_scores, labels)\n",
    "metrics(energy_scores, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
